\clearpage

\section{相关理论与技术基础}

本章介绍本文研究所需的相关理论与技术基础，主要包括 OCT 成像原理、深度学习基础、语义分割理论基础以及评价指标等内容，为后续章节的方法设计与实验分析提供理论支撑。

\subsection{OCT成像原理}

光学相干层析成像（Optical Coherence Tomography, OCT）是一种基于低相干干涉原理的高分辨率、非侵入性层析成像技术\upcite{Huang1991OCT}。该技术最早由 Huang 等人于 1991 年提出\upcite{Huang1991OCT}，通过检测参考光束与样品后向散射光之间的干涉信息，实现对生物组织或材料结构的微米级断层成像。OCT 技术无需外源造影剂或样品切片处理，即可实现高分辨率实时成像，在生物医学和工业检测领域具有重要应用价值\upcite{ZengHaitao_OCT_Speckle}。

\subsubsection{OCT成像基本原理}

OCT 成像系统基于低相干干涉原理，其核心结构为迈克尔逊干涉仪。系统主要由宽带光源、光纤耦合器、参考臂、样品臂、光电探测器等关键组件构成。宽带光源发出的光经光纤耦合器被分成两束：一束进入参考臂，射向可沿光轴移动的反射镜；另一束进入样品臂，在样品不同深度产生背散射光。这些背散射光和经参考镜反射的参考光在光纤耦合器处发生干涉，被探测器接收。通过分析干涉信号的强度和时延，即可重建样品的深度结构信息\upcite{HuangYiwei_OCT_WeldDepth}。

光波发生低相干干涉需要满足以下条件：光波相位差恒定、振动频率相同和振动方向一致。在 OCT 系统中，参考臂与样品臂的光程差决定了干涉信号的强度。当光程差小于光源的相干长度时，才能发生有效干涉；当光程差为零时，系统可获得最大干涉强度。OCT 系统的轴向分辨能力主要取决于光源的相干特性，其理论极限值约为相干长度的一半，该特性使得 OCT 技术能够实现微米级的纵向分辨\upcite{ZengHaitao_OCT_Speckle}。

从数学角度分析，设宽带光源对应的电场 $E_i$ 可表示为：
\begin{equation}
E_i = S(k) e^{i(kz - \omega t)}
\label{eq:oct_electric_field}
\end{equation}
其中，$S(k)$ 为电场的振幅，$k$ 为波数，$z$ 为光程，$\omega$ 为角频率。电场的振幅 $S(k)$ 可进一步表示为高斯型函数：
\begin{equation}
S(k) = \frac{1}{\Delta k \sqrt{\pi}} e^{-\frac{(k-k_0)^2}{\Delta k^2}}
\label{eq:oct_amplitude}
\end{equation}
其中，$k_0$ 为中心波长 $\lambda_0$ 的波数，$\Delta k$ 为频谱带宽。

设参考臂反射光场为 $E_R$，样品臂反射光场为 $E_S$，则单一波长的光谱干涉信号 $I_D(k)$ 可表示为：
\begin{equation}
I_D(k) \approx |E_R|^2 + |E_S|^2 + 2r_R r_S S(k) \cos[2k(z_R - z_S)]
\label{eq:oct_interference}
\end{equation}
其中，$r_R$ 和 $r_S$ 分别为参考臂和样品臂的光束反射率，$z_R$ 和 $z_S$ 分别为参考臂和样品臂的光程长度。干涉信号由直流项和交叉干涉项组成，交叉干涉项包含了样品的深度信息。对 $I_D(k)$ 进行快速傅里叶变换即可得到相应的深度信息，从而重建样品的层析结构\upcite{HuangYiwei_OCT_WeldDepth}。

\subsubsection{OCT技术分类}

根据不同的成像原理和数据采集方式，OCT 技术主要分为时域 OCT（Time Domain OCT, TD-OCT）和频域 OCT（Fourier Domain OCT, FD-OCT）两大类\upcite{ZengHaitao_OCT_Speckle}。

\textbf{时域 OCT} 是最早提出的 OCT 技术，通过机械扫描参考臂的延时调制，逐点扫描获得不同深度处的反射信号。时域 OCT 的成像过程包括两个步骤：一是通过参考臂的移动实现深度扫描，从干涉信号中提取样品的深度结构；二是结合横向扫描，构建二维或三维层析图像。时域 OCT 通过调节参考臂的扫描范围来灵活设定测量深度，但由于其深度信息依赖机械扫描，导致扫描时间较长、成像速度较慢，并容易受到扫描噪声干扰\upcite{ZengHaitao_OCT_Speckle}。图 \ref{fig:tdoct_system} 展示了时域 OCT 系统的基本结构。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{figure/cp2/fig2-1_tdoct_system.png}
    \caption{时域OCT系统原理示意图}
    \label{fig:tdoct_system}
\end{figure}

\textbf{频域 OCT} 通过获取完整的光谱干涉信号，并利用傅里叶变换重建深度信息，避免了机械扫描的需求，显著提高了成像速度。频域 OCT 根据光源和探测方式的差异，又可分为谱域 OCT（Spectral Domain OCT, SD-OCT）和扫频 OCT（Swept Source OCT, SS-OCT）。谱域 OCT 使用宽带光源和光谱仪，在空间域中分离干涉光并获取干涉光谱；扫频 OCT 采用宽带扫频光源和高速光电探测器，通过扫频光源在时间域内依次发射不同波长的光，并利用光电探测器在时间域中分离干涉光谱。相比谱域 OCT，扫频 OCT 在信噪比、探测灵敏度和系统分辨率方面具有更高的潜力，尤其适用于高分辨率和大视场成像\upcite{HuangYiwei_OCT_WeldDepth}。图 \ref{fig:sdoct_system} 展示了频域 OCT（谱域 OCT）系统的基本结构。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{figure/cp2/fig2-2_sdoct_system.png}
    \caption{频域OCT（谱域OCT）系统原理示意图}
    \label{fig:sdoct_system}
\end{figure}

\subsubsection{OCT在激光焊接中的应用}

在激光焊接场景中，OCT 技术通过测量光束获取匙孔（Keyhole）底部反射信息，从而为熔深在线测量提供直接的几何依据\upcite{HuangYiwei_OCT_WeldDepth}。相较于仅能反映表面辐射或二维表观信息的视觉/光电监测方法，OCT 在表征深度结构方面更具优势。激光焊接区域的反射散射光与参考臂的镜面反射光之间相位差并不恒定，因此激光加工区域的散射光与参考臂的反射光不会发生干涉，谱域 OCT 成像系统几乎不受激光加工光束的反射散射光影响，这使得 OCT 技术在激光焊接过程监测中具有独特的应用优势\upcite{HuangYiwei_OCT_WeldDepth}。

\subsubsection{OCT图像特点}

尽管 OCT 具备高分辨率、非侵入性等优势，但在实际应用中仍面临信号不稳定与噪声干扰等挑战。OCT 图像的主要特点包括：

\textbf{（1）散斑噪声}：OCT 成像基于低相干干涉原理，散斑噪声来源于相干叠加与多次散射等因素，常表现为随机颗粒纹理并伴随局部对比度下降\upcite{ZengHaitao_OCT_Speckle}。焊接过程中的熔池波动、金属蒸汽与飞溅会进一步降低信号稳定性，加剧散斑噪声的影响\upcite{HuangYiwei_OCT_WeldDepth}。

\textbf{（2）对比度低}：由于散斑噪声的存在，OCT 图像的局部对比度往往较低，特别是在弱反射区域，目标与背景的灰度差异不明显，增加了后续处理的难度。

\textbf{（3）边界模糊}：在激光焊接 OCT 图像中，锁孔边缘往往呈现对比度低、边界模糊与形态快速变化等特点，传统阈值分割、边缘检测或简单滤波难以在鲁棒性与边界保持之间取得平衡\upcite{HuangYiwei_OCT_WeldDepth}。

上述特点使得 OCT 图像中的目标区域（如锁孔）提取成为一项具有挑战性的任务，需要采用更加鲁棒的图像处理方法，这也是本文研究面向 OCT 图像的语义分割方法的重要动机。

\subsection{深度学习基础}

深度学习作为机器学习的重要分支，通过构建具有多个隐藏层的神经网络，能够自动学习数据的层次化特征表示。在图像处理领域，卷积神经网络（Convolutional Neural Network, CNN）凭借其强大的特征提取能力，已成为语义分割等视觉任务的主流方法。本节介绍深度学习的基础理论，包括卷积神经网络、编码器-解码器架构以及注意力机制等核心概念。

\subsubsection{卷积神经网络基础}

卷积神经网络是一种专门用于处理具有网格结构数据（如图像）的深度学习模型。CNN 的核心思想是通过局部连接、权值共享和池化操作，有效减少参数量并提取平移不变的特征。

\textbf{（1）卷积层}：卷积层是 CNN 的基本组成单元，通过卷积核（滤波器）在输入特征图上滑动，计算局部区域的加权和。设输入特征图为 $\mathbf{X} \in \mathbb{R}^{H \times W \times C}$，卷积核为 $\mathbf{K} \in \mathbb{R}^{k \times k \times C}$，则卷积操作可表示为：
\begin{equation}
Y_{i,j} = \sum_{m=0}^{k-1} \sum_{n=0}^{k-1} \sum_{c=0}^{C-1} X_{i+m,j+n,c} \cdot K_{m,n,c} + b
\label{eq:convolution}
\end{equation}
其中，$Y_{i,j}$ 为输出特征图在位置 $(i,j)$ 的值，$b$ 为偏置项。卷积操作具有局部连接和权值共享的特性，能够有效提取图像的局部特征（如边缘、纹理等），同时大幅减少参数量。

\textbf{（2）池化层}：池化层通过下采样操作降低特征图的空间分辨率，减少计算量并增强特征的平移不变性。常用的池化操作包括最大池化（Max Pooling）和平均池化（Average Pooling）。最大池化选择局部区域内的最大值，能够保留显著特征；平均池化计算局部区域的平均值，能够平滑特征响应。

\textbf{（3）激活函数}：激活函数为网络引入非线性，使网络能够学习复杂的非线性映射关系。常用的激活函数包括：
\begin{itemize}
    \item \textbf{ReLU（Rectified Linear Unit）}：$f(x) = \max(0, x)$，具有计算简单、梯度稳定等优点，是目前最常用的激活函数。
    \item \textbf{Sigmoid}：$f(x) = \frac{1}{1+e^{-x}}$，输出范围在 $(0,1)$ 之间，常用于二分类任务的输出层。
    \item \textbf{Softmax}：$f(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}$，将输入向量归一化为概率分布，常用于多分类任务的输出层。
\end{itemize}

\textbf{（4）批归一化}：批归一化（Batch Normalization）通过在训练过程中对每个批次的数据进行归一化，能够加速网络训练、提高模型稳定性并允许使用更大的学习率\upcite{ioffe2015batchnormalizationacceleratingdeep}。批归一化的操作可表示为：
\begin{equation}
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}, \quad y_i = \gamma \hat{x}_i + \beta
\label{eq:batch_norm}
\end{equation}
其中，$\mu_B$ 和 $\sigma_B^2$ 分别为批次数据的均值和方差，$\gamma$ 和 $\beta$ 为可学习的缩放和偏移参数，$\epsilon$ 为小常数以防止除零。

\textbf{（5）残差连接}：残差连接（Residual Connection）通过将输入直接传递到输出，解决了深层网络的梯度消失问题，使得训练更深的网络成为可能\upcite{He2015ResNet}。残差块的结构可表示为：
\begin{equation}
\mathbf{y} = \mathcal{F}(\mathbf{x}, \{\mathbf{W}_i\}) + \mathbf{x}
\label{eq:residual}
\end{equation}
其中，$\mathcal{F}(\mathbf{x}, \{\mathbf{W}_i\})$ 为残差映射，$\mathbf{x}$ 为恒等映射。残差连接使得网络能够学习残差而非完整的映射，从而简化了优化过程。ResNet 通过引入残差连接，成功训练了包含数百层的深层网络，在图像分类、目标检测等任务中取得了显著成果\upcite{He2015ResNet}。

\subsubsection{编码器-解码器架构}

编码器-解码器（Encoder-Decoder）架构是语义分割任务中常用的网络结构，通过编码器提取多尺度特征，解码器恢复空间分辨率并输出像素级预测结果\upcite{Ronneberger2015UNet}。

\textbf{（1）编码器}：编码器通常采用预训练的 CNN 骨干网络（如 ResNet、VGG 等），通过逐层卷积和下采样操作，将输入图像转换为高维特征表示。编码过程逐步降低特征图的空间分辨率，同时增加通道数，提取从低级到高级的语义特征。例如，ResNet 编码器通常包含多个阶段（Stage），每个阶段通过卷积和下采样操作，将特征图尺寸减半、通道数加倍，最终得到高维的语义特征表示。

\textbf{（2）解码器}：解码器通过上采样和特征融合操作，逐步恢复特征图的空间分辨率，并输出与输入图像尺寸相同的预测结果。上采样操作通常采用双线性插值或转置卷积实现。解码器还通过跳跃连接（Skip Connection）融合编码器不同阶段的特征，结合低层细节信息和高层语义信息，提升分割精度。

\textbf{（3）跳跃连接}：跳跃连接将编码器的中间特征直接传递到解码器的对应层，使得解码器能够利用编码器提取的多尺度特征。U-Net 架构通过 U 形的跳跃连接，将编码器的特征图与解码器对应层的特征图进行拼接，有效融合了细节信息和语义信息，在医学图像分割等任务中取得了优异性能\upcite{Ronneberger2015UNet}。

\subsubsection{注意力机制基础}

注意力机制通过动态分配不同权重，使网络能够关注输入数据中的重要部分，从而提升模型的表达能力。在计算机视觉任务中，注意力机制主要包括自注意力、空间注意力和通道注意力等类型。

\textbf{（1）自注意力机制}：自注意力（Self-Attention）机制通过计算特征图中不同位置之间的相关性，建立长距离依赖关系\upcite{vaswani2017attentionneed}。自注意力的计算过程可表示为：
\begin{equation}
\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}}\right)\mathbf{V}
\label{eq:self_attention}
\end{equation}
其中，$\mathbf{Q}$、$\mathbf{K}$、$\mathbf{V}$ 分别为查询（Query）、键（Key）和值（Value）矩阵，$d_k$ 为键向量的维度。自注意力机制能够捕获特征图中任意两个位置之间的依赖关系，不受空间距离限制，在长距离依赖建模方面具有优势。

\textbf{（2）Transformer 架构}：Transformer 架构完全基于自注意力机制，摒弃了传统的卷积和循环结构，通过多头自注意力和前馈网络构建深层网络\upcite{vaswani2017attentionneed}。Vision Transformer（ViT）将 Transformer 架构应用于图像分类任务，将图像分割为固定大小的图像块（Patch），并将每个图像块视为一个序列元素，通过自注意力机制建模图像块之间的关系\upcite{dosovitskiy2020imageworth16x16words}。Transformer 架构在图像分割任务中也得到了广泛应用，通过增强长距离依赖建模能力，提升了分割性能。

\textbf{（3）空间注意力与通道注意力}：空间注意力关注特征图的空间位置信息，通过生成空间权重图，突出重要的空间区域；通道注意力关注特征图的通道维度，通过生成通道权重向量，突出重要的特征通道。空间注意力和通道注意力可以单独使用，也可以组合使用，通过空间和通道维度的双重增强，提升特征的判别能力。本文后续章节提出的 SAE 模块即结合了空间注意力和通道注意力，用于增强局部细节和边界信息。

\subsection{语义分割理论基础}

语义分割是计算机视觉中的一项重要任务，旨在对图像中的每个像素进行分类，为每个像素分配一个语义类别标签。与图像分类和目标检测不同，语义分割需要在像素级别进行预测，要求模型同时具备强大的特征提取能力和精确的空间定位能力。本节介绍语义分割的发展历程和关键技术，包括全卷积网络、U-Net 架构以及 DeepLab 系列方法。

\subsubsection{全卷积网络}

全卷积网络（Fully Convolutional Networks, FCN）是首个将深度卷积神经网络成功应用于语义分割任务的方法\upcite{Long2015FCN}。FCN 的核心思想是将传统 CNN 中的全连接层替换为卷积层，使得网络能够接受任意尺寸的输入图像，并输出与输入尺寸相同的分割结果。

FCN 通过将预训练的分类网络（如 VGG、ResNet）转换为全卷积结构，利用卷积层的平移不变性，实现了端到端的像素级预测。FCN 还引入了跳跃连接机制，通过融合不同尺度的特征图，结合浅层的细节信息和深层的语义信息，提升了分割精度。FCN 的提出标志着深度学习在语义分割领域的成功应用，为后续研究奠定了基础\upcite{Long2015FCN}。

\subsubsection{U-Net架构}

U-Net 是一种经典的编码器-解码器架构，最初设计用于医学图像分割任务\upcite{Ronneberger2015UNet}。U-Net 采用对称的 U 形结构，编码器通过卷积和下采样逐步提取特征，解码器通过上采样和卷积逐步恢复分辨率。

U-Net 的关键创新在于其密集的跳跃连接设计：编码器每一层的特征图都与解码器对应层的特征图进行拼接，使得解码器能够充分利用编码器提取的多尺度特征。这种设计使得 U-Net 在保持高分辨率细节的同时，能够利用深层的语义信息，在医学图像分割等需要精确边界定位的任务中表现出色\upcite{Ronneberger2015UNet}。U-Net 的成功也启发了后续许多编码器-解码器架构的设计。

\subsubsection{DeepLab系列方法}

DeepLab 系列方法是语义分割领域的重要里程碑，通过引入空洞卷积和空间金字塔池化等技术，显著提升了分割性能。DeepLab 系列的发展历程体现了语义分割技术的演进轨迹。

\textbf{（1）DeepLabV1}：DeepLabV1 首次将空洞卷积（Atrous Convolution）引入语义分割任务\upcite{Chen2014DeepLabV1}。空洞卷积通过在卷积核中插入零值，在不增加参数量的情况下扩大感受野，使得网络能够在保持特征图分辨率的同时捕获更大范围的上下文信息。空洞卷积的数学表达可写为：
\begin{equation}
y[i] = \sum_{k} x[i + r \cdot k] \cdot w[k]
\label{eq:atrous_conv}
\end{equation}
其中，$r$ 为空洞率（dilation rate），控制感受野的大小。当 $r=1$ 时，空洞卷积退化为标准卷积；当 $r>1$ 时，空洞卷积能够在不增加参数量的情况下扩大感受野。

\textbf{（2）DeepLabV2}：DeepLabV2 在 DeepLabV1 的基础上引入了空间金字塔池化（Atrous Spatial Pyramid Pooling, ASPP）模块\upcite{Chen2016DeepLabV2}。ASPP 模块通过并行使用多个不同空洞率的空洞卷积，在不同尺度上捕获上下文信息，然后将多尺度特征进行融合。ASPP 模块的设计使得网络能够同时关注局部细节和全局上下文，提升了分割性能。

\textbf{（3）DeepLabV3}：DeepLabV3 对 ASPP 模块进行了改进，引入了全局平均池化分支，并优化了空洞率的选择策略\upcite{Chen2017DeepLabV3}。改进后的 ASPP 模块包含多个并行分支：不同空洞率的空洞卷积分支用于捕获多尺度上下文信息，全局平均池化分支用于捕获全局上下文信息。这些分支的特征经过拼接和融合，形成丰富的多尺度特征表示。

\textbf{（4）DeepLabV3+}：DeepLabV3+ 在 DeepLabV3 的基础上引入了编码器-解码器结构\upcite{Chen2018DeepLab}。DeepLabV3+ 采用 DeepLabV3 的输出作为编码器特征，通过解码器逐步上采样并融合编码器的中间特征，最终输出高分辨率的分割结果。DeepLabV3+ 的解码器设计简洁高效，通过融合低层细节信息和高层语义信息，在保持分割精度的同时提升了边界定位的准确性。DeepLabV3+ 是本文方法的基础框架，其编码器-解码器结构和 ASPP 模块为本文的改进提供了良好的起点。

\subsubsection{多尺度特征融合策略}

多尺度特征融合是语义分割中的关键技术，旨在结合不同尺度的特征信息，提升模型对不同大小目标的处理能力。除了 ASPP 模块外，特征金字塔网络（Feature Pyramid Network, FPN）也是一种重要的多尺度特征融合方法\upcite{Lin2016FPN}。

FPN 通过构建特征金字塔，在不同尺度上提取特征，并通过自上而下的路径和横向连接融合多尺度特征。FPN 的设计使得网络能够在不同尺度上检测目标，提升了模型对多尺度目标的处理能力。虽然 FPN 最初设计用于目标检测任务，但其多尺度特征融合的思想在语义分割任务中也得到了广泛应用。

近年来，Transformer 架构也被引入语义分割任务，通过自注意力机制增强长距离依赖建模能力。TransUNet 将 Transformer 作为编码器，结合 U-Net 的解码器结构，在医学图像分割任务中取得了优异性能\upcite{TransUNet2021}。Transformer 架构的引入为语义分割提供了新的思路，但其计算复杂度较高，在实际应用中需要权衡性能与效率。

\subsection{语义分割评价指标}

为了客观评估语义分割模型的性能，需要采用合适的评价指标对预测结果进行定量分析。语义分割的评价指标通常基于混淆矩阵（Confusion Matrix）计算，通过比较预测结果与真实标签之间的差异，量化模型的分割精度。本节介绍常用的语义分割评价指标及其计算方法。

\subsubsection{混淆矩阵}

混淆矩阵是评估分类模型性能的基础工具，用于统计预测结果与真实标签之间的对应关系。对于语义分割任务，混淆矩阵 $C$ 是一个 $N \times N$ 的矩阵，其中 $N$ 为类别数。矩阵元素 $C_{ij}$ 表示真实类别为 $i$、预测类别为 $j$ 的像素数量。

基于混淆矩阵，可以计算多种评价指标。对于二分类任务（如本文的锁孔分割任务），混淆矩阵包含四个元素：真正例（True Positive, TP）、假正例（False Positive, FP）、真负例（True Negative, TN）和假负例（False Negative, FN）。

\subsubsection{像素准确率}

像素准确率（Pixel Accuracy, PA）是最直观的评价指标，表示正确分类的像素占总像素的比例：
\begin{equation}
\text{PA} = \frac{\sum_{i=0}^{N-1} C_{ii}}{\sum_{i=0}^{N-1} \sum_{j=0}^{N-1} C_{ij}}
\label{eq:pixel_accuracy}
\end{equation}
其中，$C_{ii}$ 为混淆矩阵对角线元素，表示正确分类的像素数；分母为总像素数。PA 的取值范围为 $[0, 1]$，值越大表示分割精度越高。

PA 指标计算简单直观，但在类别不平衡的情况下（如背景像素远多于目标像素），PA 可能无法准确反映模型对少数类别的分割性能。例如，在锁孔分割任务中，背景区域通常占据图像的大部分，即使模型将所有像素预测为背景，PA 值也可能较高，但这并不能说明模型的分割性能良好。

\subsubsection{平均像素准确率}

平均像素准确率（Mean Pixel Accuracy, mPA）通过计算每个类别的像素准确率并取平均，能够更好地反映模型对不同类别的分割性能：
\begin{equation}
\text{mPA} = \frac{1}{N} \sum_{i=0}^{N-1} \frac{C_{ii}}{\sum_{j=0}^{N-1} C_{ij}}
\label{eq:mean_pixel_accuracy}
\end{equation}
其中，$\frac{C_{ii}}{\sum_{j=0}^{N-1} C_{ij}}$ 表示类别 $i$ 的像素准确率，即类别 $i$ 中正确分类的像素数占该类别总像素数的比例。mPA 对每个类别赋予相同的权重，能够更好地评估模型在类别不平衡情况下的性能。

\subsubsection{交并比}

交并比（Intersection over Union, IoU）是语义分割任务中最常用的评价指标之一，表示预测结果与真实标签的交集与并集的比值：
\begin{equation}
\text{IoU}_i = \frac{C_{ii}}{\sum_{j=0}^{N-1} C_{ij} + \sum_{j=0}^{N-1} C_{ji} - C_{ii}}
\label{eq:iou}
\end{equation}
其中，分子 $C_{ii}$ 为类别 $i$ 的预测结果与真实标签的交集（正确预测的像素数），分母为两者的并集（预测为类别 $i$ 或真实为类别 $i$ 的像素总数）。IoU 的取值范围为 $[0, 1]$，值越大表示分割精度越高。

IoU 指标能够同时考虑预测结果的准确性和完整性，对分割边界的精度更加敏感，因此在语义分割任务中被广泛采用。对于二分类任务，IoU 的计算可简化为：
\begin{equation}
\text{IoU} = \frac{\text{TP}}{\text{TP} + \text{FP} + \text{FN}}
\label{eq:iou_binary}
\end{equation}

\subsubsection{平均交并比}

平均交并比（Mean Intersection over Union, mIoU）通过计算所有类别 IoU 的平均值，综合评估模型的分割性能：
\begin{equation}
\text{mIoU} = \frac{1}{N} \sum_{i=0}^{N-1} \text{IoU}_i
\label{eq:mean_iou}
\end{equation}
mIoU 是语义分割任务中最常用的评价指标，能够综合反映模型对不同类别的分割性能。在类别不平衡的情况下，mIoU 比 PA 更能准确反映模型的真实性能。本文实验部分将 mIoU 作为主要评价指标，用于评估不同方法的分割性能。

\subsubsection{Dice系数}

Dice 系数（Dice Coefficient）是医学图像分割中常用的评价指标，表示预测结果与真实标签的重叠程度：
\begin{equation}
\text{Dice}_i = \frac{2 \cdot C_{ii}}{2 \cdot C_{ii} + \sum_{j \neq i} C_{ij} + \sum_{j \neq i} C_{ji}} = \frac{2 \cdot \text{TP}}{2 \cdot \text{TP} + \text{FP} + \text{FN}}
\label{eq:dice}
\end{equation}
Dice 系数的取值范围为 $[0, 1]$，值越大表示重叠程度越高。对于二分类任务，Dice 系数与 IoU 之间存在以下关系：
\begin{equation}
\text{Dice} = \frac{2 \cdot \text{IoU}}{1 + \text{IoU}}
\label{eq:dice_iou_relation}
\end{equation}
Dice 系数对分割区域的完整性更加敏感，在医学图像分割等需要精确区域分割的任务中应用广泛。本文在损失函数设计中采用了 Dice 损失，用于处理类别不平衡问题。

\subsubsection{评价指标的适用场景}

不同的评价指标适用于不同的场景和需求：

\textbf{（1）PA}：适用于类别分布相对均衡的场景，计算简单直观，但在类别不平衡情况下可能产生误导性结果。

\textbf{（2）mPA}：通过平均各类别的准确率，能够更好地评估类别不平衡情况下的性能，但对每个类别赋予相同权重，可能忽略类别的重要性差异。

\textbf{（3）IoU 和 mIoU}：综合考虑预测结果的准确性和完整性，对分割边界精度敏感，是语义分割任务中最常用的评价指标。mIoU 能够综合反映模型对不同类别的分割性能，适用于多类别分割任务。

\textbf{（4）Dice 系数}：对分割区域的完整性更加敏感，在医学图像分割等需要精确区域分割的任务中应用广泛。Dice 系数与 IoU 相关但侧重点不同，可以根据具体任务需求选择合适的指标。

在实际应用中，通常同时使用多个评价指标，从不同角度全面评估模型性能。本文实验部分将同时报告 mIoU、PA、mPA 和 Dice 系数等指标，以全面评估所提方法的分割性能。

\subsection{本章小结}

本章介绍了本文研究所需的相关理论与技术基础，为后续章节的方法设计与实验分析提供了理论支撑。

首先，本章介绍了 OCT 成像原理，包括 OCT 技术的基本原理、技术分类以及在激光焊接中的应用。OCT 技术基于低相干干涉原理，能够实现微米级的高分辨率层析成像，在激光焊接场景中可用于锁孔检测和熔深测量。然而，OCT 图像存在散斑噪声、对比度低、边界模糊等特点，使得目标区域的提取成为一项具有挑战性的任务，这也为本文研究面向 OCT 图像的语义分割方法提供了重要动机。

其次，本章介绍了深度学习的基础理论，包括卷积神经网络、编码器-解码器架构以及注意力机制等核心概念。卷积神经网络通过局部连接、权值共享和池化操作，能够有效提取图像特征；编码器-解码器架构通过编码器提取多尺度特征、解码器恢复空间分辨率，实现了端到端的像素级预测；注意力机制通过动态分配权重，使网络能够关注重要信息，提升了模型的表达能力。这些理论基础为本文方法的设计提供了重要支撑。

再次，本章回顾了语义分割的发展历程和关键技术，包括全卷积网络、U-Net 架构以及 DeepLab 系列方法。DeepLabV3+ 作为本文方法的基础框架，通过编码器-解码器结构和 ASPP 模块，实现了多尺度上下文信息的有效捕获。然而，在处理 OCT 图像时，DeepLabV3+ 仍存在全局上下文信息利用不足和局部细节丢失等问题，这为本文的改进提供了方向。

最后，本章介绍了语义分割常用的评价指标，包括像素准确率、平均像素准确率、交并比、平均交并比以及 Dice 系数等。这些评价指标从不同角度量化模型的分割性能，为后续章节的实验评估提供了标准。

基于本章介绍的理论基础，本文将在第三章提出一种基于改进 DeepLabV3+ 的 OCT 图像语义分割方法。该方法在编码器端引入 TR 模块以增强全局上下文建模能力，在解码器端引入 SAE 模块以增强局部细节和边界信息，从而实现对锁孔区域的高精度分割。第四章将基于本章介绍的评价指标，对所提方法进行全面的实验验证和性能分析。