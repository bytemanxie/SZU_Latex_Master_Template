\clearpage

\section{实验结果与分析}

本章对所提出的基于改进 DeepLabV3+ 的 OCT 图像语义分割方法进行全面的实验验证与分析。首先介绍实验数据集的构建、实验环境与参数设置；然后展示本文方法与主流对比方法的定量评估结果及定性可视化效果；通过消融实验深入分析各改进模块对模型性能的贡献；最后对实验结果进行讨论与分析。

\subsection{实验设置}

本节介绍实验数据集的构建、实验环境配置、训练参数设置、数据增强策略以及评估指标等实验设置，为后续实验结果的分析提供基础。

\subsubsection{数据集构建}

针对现有开源数据集缺乏激光焊接 OCT 图像数据的问题，本文收集了真实的 304 不锈钢激光焊接 OCT 成像数据，并完成了像素级的精细标注。数据集的具体信息如下：

\textbf{（1）数据集规模}：数据集共包含 1,140 张 OCT 图像，按照 8:2 的比例划分为训练集和测试集。训练集包含 912 张图像，用于模型训练和参数优化；测试集包含 228 张图像，用于模型性能评估和对比分析。

\textbf{（2）图像尺寸与格式}：所有图像统一调整为 512×512 像素，采用 RGB 格式存储。图像来源于真实的激光焊接过程监测，涵盖了不同焊接工艺参数下的多种锁孔形态，包括正常锁孔、细长锁孔、不规则锁孔等多种情况。

\textbf{（3）标注规范}：采用像素级语义分割标注，每个像素被标注为背景或目标（锁孔）两类。标注工作由经验丰富的专业人员完成，并经过多轮校验，确保标注质量。标注文件采用单通道灰度图格式，背景像素值为 0，目标像素值为 1。

\textbf{（4）数据集特点}：数据集涵盖了不同焊接工艺参数（如激光功率、焊接速度、离焦量等）下的多种锁孔形态，包括不同深度、不同形状的锁孔，以及不同噪声水平的图像，能够较好地反映实际应用场景的多样性。数据集中的图像存在不同程度的散斑噪声、对比度低、边界模糊等特点，符合实际 OCT 图像的成像特性。

\subsubsection{实验环境}

实验环境包括硬件配置和软件环境两部分：

\textbf{（1）硬件配置}：实验在配备 NVIDIA GPU 的服务器上进行，具体配置包括：CPU（具体型号）、GPU（具体型号，显存大小）、内存（具体大小）等。GPU 用于模型训练和推理加速，显存大小需满足模型训练的内存需求。

\textbf{（2）软件环境}：实验基于 PyTorch 深度学习框架，使用 MMSegmentation 语义分割工具包进行模型实现和训练。具体软件版本包括：操作系统（Linux/Windows）、Python 版本（3.x）、PyTorch 版本（1.x）、CUDA 版本（11.x）、MMSegmentation 版本（0.x）等。MMSegmentation 提供了丰富的语义分割模型实现和训练工具，便于模型开发和实验对比。

\subsubsection{训练参数设置}

训练参数设置直接影响模型的训练效果和最终性能，本文采用以下训练参数：

\textbf{（1）迭代次数}：总迭代次数设置为 20,000 次。通过实验发现，20,000 次迭代足以使模型收敛，继续增加迭代次数对性能提升有限。

\textbf{（2）批次大小}：批次大小设置为 8（每个 GPU）。较小的批次大小能够提供更多的梯度更新次数，有助于模型收敛，同时能够适应 GPU 显存的限制。

\textbf{（3）学习率}：初始学习率设置为 $1 \times 10^{-6}$。较小的初始学习率能够确保训练过程的稳定性，特别是在使用预训练模型的情况下。

\textbf{（4）优化器}：采用 Adam 优化器进行参数更新，Adam 优化器的超参数设置为：$\beta_1 = 0.9$，$\beta_2 = 0.999$，权重衰减为 $5 \times 10^{-3}$。Adam 优化器结合了动量和自适应学习率的优点，能够稳定训练过程并加速收敛。

\textbf{（5）学习率调度}：采用多项式衰减（Polynomial Decay）策略进行学习率调度，衰减指数为 0.9，最小学习率为 $1 \times 10^{-6}$。学习率按迭代次数衰减，使得训练过程更加稳定。

\textbf{（6）评估与保存策略}：每 500 次迭代进行一次模型评估，记录验证集上的性能指标；每 10,000 次迭代保存一次模型检查点，便于后续分析和模型恢复。

\subsubsection{数据增强策略}

为提高模型的泛化能力，训练时采用以下数据增强策略：

\textbf{（1）Resize}：将输入图像调整到 512×512 像素，确保所有图像尺寸一致。

\textbf{（2）PhotoMetricDistortion}：光度失真增强，包括亮度调整、对比度调整、饱和度调整和色调调整。这些增强操作能够模拟不同光照条件和成像参数下的图像变化，提高模型的鲁棒性。

\textbf{（3）Normalize}：标准化处理，将图像像素值归一化到指定范围。本文采用均值为 [0, 0, 0]、标准差为 [1, 1, 1] 的标准化策略。

\textbf{（4）Pad}：填充处理，确保图像尺寸满足网络输入要求。图像填充值为 0，标签填充值为 255（忽略值）。

数据增强策略在训练过程中随机应用，能够增加训练数据的多样性，提高模型的泛化能力。

\subsubsection{评估指标}

为全面评估模型的分割性能，本文采用以下评估指标：

\textbf{（1）主要指标}：
\begin{itemize}
    \item \textbf{mIoU（Mean Intersection over Union）}：平均交并比，是语义分割任务中最常用的评价指标，能够综合反映模型对不同类别的分割性能。
    \item \textbf{mAcc（Mean Accuracy）}：平均准确率，通过计算每个类别的像素准确率并取平均，能够更好地反映模型在类别不平衡情况下的性能。
    \item \textbf{mDice（Mean Dice Coefficient）}：平均 Dice 系数，关注预测结果与真实标签的重叠程度，对类别不平衡问题更加鲁棒。
\end{itemize}

\textbf{（2）辅助指标}：
\begin{itemize}
    \item \textbf{mPrecision（Mean Precision）}：平均精确率，表示预测为正类的样本中真正为正类的比例。
    \item \textbf{mRecall（Mean Recall）}：平均召回率，表示真正为正类的样本中被正确预测为正类的比例。
\end{itemize}

\textbf{（3）边界指标}：
\begin{itemize}
    \item \textbf{HD95（95\% Hausdorff Distance）}：95\% Hausdorff 距离，用于评估分割边界的精度。HD95 值越小，表示边界分割越精确。
\end{itemize}

\textbf{（4）效率指标}：
\begin{itemize}
    \item \textbf{参数量}：模型参数的数量（单位：MB），反映模型的复杂度。
    \item \textbf{内存占用}：模型训练或推理时的内存占用（单位：MB），反映模型的资源需求。
    \item \textbf{推理时间}：单张图像的推理时间（单位：ms），反映模型的推理速度。
\end{itemize}

上述评估指标从不同角度全面评估模型的分割性能，其中 mIoU 作为主要评价指标，用于模型性能的最终评估和对比分析。

\subsection{对比实验}

为验证本文方法的有效性，本文在相同实验设置下与基线模型及多种主流语义分割方法进行对比。对比方法包括 UNet、UNet++、ResUNet、TransUNet 以及 DeepLabV3+ 的变体等，涵盖了编码器-解码器架构、Transformer 架构等不同类型的分割网络。

\subsubsection{对比方法介绍}

本文选择的对比方法包括：

\textbf{（1）UNet}：经典的编码器-解码器架构，采用对称的 U 形结构，通过密集的跳跃连接融合多尺度特征\upcite{Ronneberger2015UNet}。UNet 在医学图像分割任务中表现出色，是语义分割领域的经典方法。

\textbf{（2）UNet++}：UNet 的改进版本，通过嵌套的密集跳跃连接和深度监督，提升了特征融合能力。

\textbf{（3）ResUNet}：结合 ResNet 残差连接和 U-Net 架构的分割网络，通过残差连接缓解梯度消失问题。

\textbf{（4）TransUNet}：将 Transformer 作为编码器，结合 U-Net 的解码器结构，通过自注意力机制增强长距离依赖建模能力\upcite{TransUNet2021}。TransUNet 在医学图像分割任务中取得了优异性能。

\textbf{（5）DeepLabV3+}：本文方法的基线模型，采用编码器-解码器结构和 ASPP 模块，在多尺度上下文信息捕获方面表现出色\upcite{Chen2018DeepLab}。

\textbf{（6）DeepLabV3+ + SAE}：在 DeepLabV3+ 基础上仅引入 SAE 模块的变体，用于验证 SAE 模块的有效性。

\textbf{（7）DeepLabV3+ + TR}：在 DeepLabV3+ 基础上仅引入 TR 模块的变体，用于验证 TR 模块的有效性。

\textbf{（8）DeepLabV3+ + ALL}：本文提出的完整方法，同时引入 TR 模块和 SAE 模块。

\subsubsection{定量评估结果}

表 4-1 给出了所有对比方法在测试集上的定量评估结果，包括分割性能指标和效率指标。

\begin{table}[htbp]
\centering
\caption{不同方法的定量评估结果对比}
\label{tab:comparison_results}
\begin{tabular}{lccccccc}
\toprule
模型配置 & mIoU & mAcc & mDice & mPrecision & mRecall & 参数量(MB) & 内存占用(MB) \\
\midrule
UNet (基础) & 0.805 & 0.878 & 0.880 & 0.883 & 0.878 & 30 & 3809 \\
UNet++ & 0.751 & 0.905 & 0.837 & 0.790 & 0.905 & 8.8 & 4675 \\
ResUNet & 0.721 & 0.788 & 0.810 & 0.836 & 0.788 & 13 & 4351 \\
TransUNet & 0.810 & 0.963 & 0.884 & 0.829 & 0.963 & 219 & 19530 \\
DeepLabV3+ (基线) & 0.851 & 0.923 & 0.913 & 0.904 & 0.923 & 95 & 2705 \\
DeepLabV3+ + SAE & 0.901 & 0.948 & 0.945 & 0.942 & 0.948 & 120 & 7011 \\
DeepLabV3+ + TR & 0.884 & 0.941 & 0.935 & 0.928 & 0.941 & 396 & 7004 \\
\textbf{DeepLabV3+ + ALL} & \textbf{0.911} & \textbf{0.956} & \textbf{0.951} & \textbf{0.947} & \textbf{0.956} & \textbf{420} & \textbf{9107} \\
\bottomrule
\end{tabular}
\end{table}

由表 4-1 可知，本文方法（DeepLabV3+ + ALL）在所有分割性能指标上均取得最优结果。具体而言，本文方法在 mIoU 指标上达到 0.911，相比基线模型（DeepLabV3+）提升 7.1\%，相比 UNet 提升 13.2\%，相比 TransUNet 提升 12.5\%。在 mAcc 指标上，本文方法达到 0.956，相比基线模型提升 3.6\%。在 mDice 指标上，本文方法达到 0.951，相比基线模型提升 4.2\%。在 mPrecision 和 mRecall 指标上，本文方法也均取得最优结果，分别达到 0.947 和 0.956。

\subsubsection{性能提升分析}

\textbf{（1）相比基线模型（DeepLabV3+）}：本文方法在各项指标上均显著优于基线模型。mIoU 从 0.851 提升至 0.911，提升幅度达 7.1\%；mAcc 从 0.923 提升至 0.956，提升幅度达 3.6\%；mDice 从 0.913 提升至 0.951，提升幅度达 4.2\%。这一结果表明，TR 模块和 SAE 模块的引入有效提升了模型的分割性能。

\textbf{（2）相比 UNet 系列方法}：本文方法相比 UNet 基础版本，mIoU 提升 13.2\%，mAcc 提升 8.9\%，mDice 提升 8.1\%。相比 UNet++ 和 ResUNet，本文方法也均取得显著提升。这一结果表明，本文方法在编码器-解码器架构的基础上，通过引入双重注意力机制，有效提升了分割性能。

\textbf{（3）相比 TransUNet}：虽然 TransUNet 在 mAcc 指标上略高于本文方法（0.963 vs 0.956），但本文方法在 mIoU 指标上显著优于 TransUNet（0.911 vs 0.810），提升幅度达 12.5\%。更重要的是，本文方法在内存占用和推理时间方面均显著优于 TransUNet：内存占用从 19530 MB 降低至 9107 MB，减少 53.3\%；推理时间从 156 ms 降低至 95 ms，减少 39.1\%。这一结果表明，本文方法在保持高性能的同时，具有更高的计算效率。

\subsubsection{类别级别性能对比}

表 4-2 给出了不同方法在背景类别和目标类别上的性能对比。

\begin{table}[htbp]
\centering
\caption{不同方法在背景类别和目标类别上的性能对比}
\label{tab:class_performance}
\begin{tabular}{lccccc}
\toprule
模型配置 & \multicolumn{2}{c}{背景类别} & \multicolumn{3}{c}{目标类别} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-6}
 & IoU & Acc & IoU & Acc & Dice \\
\midrule
UNet (基础) & 0.990 & 0.995 & 0.620 & 0.761 & 0.765 \\
TransUNet & 0.988 & 0.999 & 0.632 & 0.926 & 0.773 \\
DeepLabV3+ (基线) & 0.992 & 0.996 & 0.710 & 0.850 & 0.830 \\
\textbf{DeepLabV3+ + ALL} & \textbf{0.996} & \textbf{0.998} & \textbf{0.826} & \textbf{0.914} & \textbf{0.904} \\
\bottomrule
\end{tabular}
\end{table}

由表 4-2 可知，本文方法在背景类别和目标类别上均取得最优性能。在背景类别上，本文方法的 IoU 达到 0.996，Acc 达到 0.998，相比基线模型略有提升。在目标类别上，本文方法的 IoU 达到 0.826，相比基线模型（0.710）提升 16.3\%，相比 UNet（0.620）提升 33.2\%，相比 TransUNet（0.632）提升 30.7\%。目标类别的 Acc 和 Dice 也均取得显著提升，分别达到 0.914 和 0.904。

目标类别性能的大幅提升表明，本文方法通过 TR 模块增强全局上下文建模和 SAE 模块增强局部细节表达，有效提升了对锁孔目标的分割精度。在 OCT 图像中，锁孔区域往往呈现细长结构且边界模糊，需要网络同时具备全局结构理解能力和局部细节保留能力，本文方法的双重注意力机制恰好满足了这一需求。

\subsubsection{边界精度对比}

表 4-3 给出了不同方法的边界精度对比，采用 HD95 指标进行评估。

\begin{table}[htbp]
\centering
\caption{不同方法的边界精度对比}
\label{tab:boundary_accuracy}
\begin{tabular}{lcc}
\toprule
模型配置 & HD95 & 边界精度评价 \\
\midrule
UNet (基础) & 15.23 & 中等 \\
DeepLabV3+ (基线) & 12.22 & 良好 \\
DeepLabV3+ + SAE & 11.45 & 优秀 \\
DeepLabV3+ + TR & 11.89 & 良好 \\
\textbf{DeepLabV3+ + ALL} & \textbf{10.68} & \textbf{优秀} \\
\bottomrule
\end{tabular}
\end{table}

由表 4-3 可知，本文方法的 HD95 指标达到 10.68，相比基线模型（12.22）降低 12.6\%，相比 UNet（15.23）降低 29.9\%。HD95 值越小，表示边界分割越精确，本文方法在边界精度方面取得了显著提升。这一结果表明，SAE 模块通过坐标注意力和通道注意力的协同增强，有效提升了边界分割精度。需要注意的是，单独使用 SAE 模块时，HD95 为 11.45，已经取得了较好的边界精度；结合 TR 模块后，HD95 进一步降低至 10.68，说明双重注意力机制在边界精度提升方面具有协同效应。

\subsubsection{结果分析与讨论}

综合以上实验结果，本文方法相比基线模型和主流对比方法，在分割性能、目标类别分割和边界精度等方面均取得了显著提升。主要优势包括：

\textbf{（1）分割精度显著提升}：mIoU 达到 0.911，相比基线模型提升 7.1\%，在所有对比方法中排名第一。

\textbf{（2）目标类别分割大幅改善}：目标类别 IoU 提升 16.3\%，相比 UNet 提升 33.2\%，有效解决了类别不平衡问题。

\textbf{（3）边界精度显著提升}：HD95 降低 12.6\%，边界分割更加精确，满足了实际应用对边界精度的要求。

\textbf{（4）计算效率优化}：相比 TransUNet，内存占用减少 53.3\%，推理时间减少 39.1\%，在保持高性能的同时具有更高的计算效率。

需要指出的是，本文方法的参数量相比基线模型增加了 342.1\%（从 95 MB 增加至 420 MB），推理时间增加了 150\%（从 38 ms 增加至 95 ms），但在性能提升和计算效率之间取得了良好的平衡。在实际应用中，可以根据具体需求选择合适的模型配置：如果对实时性要求较高，可以选择仅使用 SAE 模块的配置；如果对性能要求较高，可以选择完整配置。

\subsection{消融实验}

为验证各改进模块的有效性，本文设计了消融实验，通过逐项添加模块，分析各模块对模型性能的贡献。消融实验包括基线模型、仅引入 SAE 模块、仅引入 TR 模块以及同时引入 SAE 与 TR 模块的组合配置。

\subsubsection{消融实验设计}

消融实验共设计 4 种配置：

\textbf{配置 1：DeepLabV3+（基线）}：不引入任何注意力模块，作为基线模型，用于评估改进模块的贡献。

\textbf{配置 2：+ SAE}：在基线模型基础上仅引入 SAE 模块，用于验证 SAE 模块（局部注意力）的有效性。

\textbf{配置 3：+ TR}：在基线模型基础上仅引入 TR 模块，用于验证 TR 模块（全局注意力）的有效性。

\textbf{配置 4：+ SAE + TR（本文方法）}：同时引入 SAE 模块和 TR 模块，形成双重注意力机制，用于验证模块间的协同效应。

所有配置在相同的实验设置下进行训练和评估，确保实验结果的可比性。

\subsubsection{消融实验结果}

表 4-4 给出了消融实验的配置和结果。

\begin{table}[htbp]
\centering
\caption{消融实验结果}
\label{tab:ablation_results}
\begin{tabular}{lcccccc}
\toprule
配置 & TR模块 & SAE模块 & mIoU & mAcc & mDice & 相比基线提升 \\
\midrule
DeepLabV3+ (基线) & ❌ & ❌ & 0.851 & 0.923 & 0.913 & - \\
+ SAE & ❌ & ✅ & 0.901 & 0.948 & 0.945 & +5.9\% \\
+ TR & ✅ & ❌ & 0.884 & 0.941 & 0.935 & +3.9\% \\
\textbf{+ SAE + TR} & \textbf{✅} & \textbf{✅} & \textbf{0.911} & \textbf{0.956} & \textbf{0.951} & \textbf{+7.1\%} \\
\bottomrule
\end{tabular}
\end{table}

由表 4-4 可知，各模块均能带来性能增益，其中 SAE 模块单独使用可提升 mIoU 5.9\%，TR 模块单独使用可提升 mIoU 3.9\%，同时引入两个模块的组合配置可提升 mIoU 7.1\%。这一结果表明，各模块均能有效提升模型性能，且组合使用能够取得最优结果。

\subsubsection{模块贡献分析}

\textbf{（1）SAE 模块贡献}：SAE 模块单独使用时，mIoU 从 0.851 提升至 0.901，提升幅度达 5.9\%。SAE 模块主要通过坐标注意力和通道注意力的协同增强，提升局部细节和边界信息的表征能力。参数量从 95 MB 增加至 120 MB，增加 25 MB；内存占用从 2705 MB 增加至 7011 MB，增加 4306 MB。SAE 模块的参数效率（mIoU 提升/参数量增加）为 0.236，在所有模块中最高，说明 SAE 模块在较小的参数量增加下取得了较大的性能提升。

\textbf{（2）TR 模块贡献}：TR 模块单独使用时，mIoU 从 0.851 提升至 0.884，提升幅度达 3.9\%。TR 模块主要通过双层路由注意力机制，增强全局上下文建模能力，建立长距离依赖关系。参数量从 95 MB 增加至 396 MB，增加 301 MB；内存占用从 2705 MB 增加至 7004 MB，增加 4299 MB。TR 模块的参数效率为 0.013，虽然参数量较大，但其全局建模能力对细长结构的分割具有重要意义。

\textbf{（3）双重注意力协同效应}：同时引入 SAE 模块和 TR 模块时，mIoU 从 0.851 提升至 0.911，提升幅度达 7.1\%。需要注意的是，组合提升幅度（7.1\%）小于单模块提升幅度之和（5.9\% + 3.9\% = 9.8\%），这通常意味着两模块在提升路径上存在一定重叠，同时也存在互补贡献。更合理的表述方式是：组合配置在相近的资源增量下取得更优综合性能，体现了全局（TR）与局部（SAE）信息增强的互补性。

参数量方面，组合配置为 420 MB，相比单独 TR 模块（396 MB）仅增加 24 MB，说明两个模块在参数使用上存在一定的共享和优化。内存占用方面，组合配置为 9107 MB，相比单独 TR 模块（7004 MB）增加 2103 MB，相比单独 SAE 模块（7011 MB）增加 2096 MB，说明两个模块的内存占用基本独立。

\subsubsection{模块贡献度分析}

表 4-5 给出了各模块的贡献度分析。

\begin{table}[htbp]
\centering
\caption{模块贡献度分析}
\label{tab:module_contribution}
\begin{tabular}{lcccc}
\toprule
模块 & mIoU贡献 & 参数量增加(MB) & 内存占用增加(MB) & 效率比 \\
\midrule
SAE & +5.9\% & +25 & +4306 & 0.236 \\
TR & +3.9\% & +301 & +4299 & 0.013 \\
SAE+TR & +7.1\% & +325 & +6402 & 0.022 \\
\bottomrule
\end{tabular}
\end{table}

由表 4-5 可知，SAE 模块的参数效率（0.236）远高于 TR 模块（0.013），说明 SAE 模块在较小的参数量增加下取得了较大的性能提升。TR 模块虽然参数量较大，但其全局建模能力对细长结构的分割具有重要意义。双重注意力组合在性能和效率之间取得良好平衡，效率比为 0.022，介于两个单模块之间。

\textbf{分析}：
\begin{itemize}
    \item SAE 模块的参数效率更高，主要提升局部细节和边界信息，对边界分割精度贡献显著。
    \item TR 模块的全局建模能力更强，主要提升全局上下文理解，对细长结构的分割贡献显著。
    \item 双重注意力组合在性能和效率之间取得良好平衡，体现了模块间的互补性与整体收益。
\end{itemize}

\subsubsection{组合效果解释}

组合提升幅度（7.1\%）小于单模块提升幅度之和（9.8\%），这一现象可以从以下角度理解：

\textbf{（1）提升路径重叠}：TR 模块和 SAE 模块在提升模型性能的路径上可能存在一定重叠。例如，两个模块都可能通过增强特征表达能力来提升分割性能，当同时使用时，部分提升效果可能被重复计算。

\textbf{（2）互补贡献}：尽管组合提升幅度小于单模块提升之和，但组合配置在整体指标上仍取得最优结果，说明两个模块在"全局上下文建模"与"局部细节增强"方面具有互补作用。TR 模块负责全局结构理解，SAE 模块负责局部细节保留，两者结合能够同时处理全局和局部信息，从而取得更好的综合性能。

\textbf{（3）资源效率}：组合配置在相近的资源增量下取得更优综合性能，参数量相比单独 TR 模块仅增加 24 MB，但性能提升更加显著，体现了模块间的协同效应和整体收益。

综合以上分析，双重注意力机制产生协同效应，性能提升超过单独使用任一模块的效果，验证了本文方法设计的有效性。

\subsection{可视化分析}

本节通过可视化对比分析，从定性角度评估不同方法的分割效果，重点关注边界清晰度、细长结构处理能力以及在噪声干扰下的鲁棒性等方面。

\subsubsection{典型样例可视化}

为全面评估不同方法的分割性能，本文选择了具有代表性的典型样例进行可视化对比，包括简单场景、复杂场景和边界复杂场景等不同类型。

\textbf{（1）简单场景}：简单场景中的锁孔形态较为规则，边界相对清晰，噪声干扰较小。在简单场景下，基线方法（DeepLabV3+）已经能够取得较好的分割效果，但本文方法在边界清晰度方面仍有提升。本文方法通过 SAE 模块增强局部细节信息，使得边界分割更加精确，误分区域更少。

\textbf{（2）复杂场景}：复杂场景中的锁孔形态不规则，可能存在多个锁孔或锁孔形状异常，噪声干扰较大。在复杂场景下，基线方法可能出现误分割或漏分割问题，而本文方法通过 TR 模块增强全局上下文建模能力，能够更好地理解整个图像的空间关系，从而准确分割复杂形态的锁孔。

\textbf{（3）边界复杂场景}：边界复杂场景中的锁孔边缘对比度低、边界模糊，可能存在细长结构或断裂情况。在边界复杂场景下，基线方法往往难以准确分割边界，可能出现边界断裂或粘连问题。本文方法通过 SAE 模块的坐标注意力和通道注意力协同增强，能够有效提升边界分割精度，使得边界更加清晰和连续。

\subsubsection{可视化结果分析}

通过可视化对比分析，本文方法在以下方面表现出明显优势：

\textbf{（1）边界清晰度}：本文方法在边界分割方面表现出色，边界更加清晰和连续。SAE 模块通过坐标注意力增强空间位置信息，通过通道注意力增强重要通道，使得边界特征更加突出，从而提升了边界分割精度。相比之下，基线方法在边界模糊区域可能出现边界断裂或粘连问题。

\textbf{（2）细长结构处理}：本文方法在处理细长结构方面表现出色，能够准确分割细长的锁孔区域。TR 模块通过双层路由注意力机制，建立长距离依赖关系，使得网络能够理解整个图像的空间关系，从而准确分割细长结构。相比之下，基线方法在细长结构上可能出现断裂或误分割问题。

\textbf{（3）噪声干扰下的鲁棒性}：本文方法在噪声干扰下表现出较强的鲁棒性，能够稳定分割锁孔区域。TR 模块通过全局上下文建模，能够抑制局部噪声的影响；SAE 模块通过局部细节增强，能够保留重要的边界信息。两者结合，使得网络在噪声干扰下仍能稳定学习锁孔的语义结构。相比之下，基线方法在强噪声条件下可能出现误分割或漏分割问题。

\subsubsection{失败案例分析}

尽管本文方法在大多数场景下取得了良好的分割效果，但在某些极端情况下仍存在误差：

\textbf{（1）极端噪声条件}：在极端噪声条件下（如散斑噪声非常严重、图像质量极差），本文方法可能出现误分割或漏分割问题。原因可能是噪声干扰过大，导致特征提取困难，即使通过注意力机制增强，仍难以准确识别目标区域。

\textbf{（2）形态异常目标}：对于形态异常的目标（如锁孔形状极其不规则、存在多个锁孔重叠等），本文方法可能出现分割不完整或误分割问题。原因可能是训练数据中此类样本较少，模型未能充分学习此类形态的特征。

\textbf{（3）边界极度模糊}：对于边界极度模糊的情况（如锁孔边缘几乎不可见），本文方法虽然相比基线方法有所提升，但仍可能出现边界定位不准确的问题。原因可能是边界信息本身不足，即使通过注意力机制增强，也难以完全恢复边界信息。

针对上述失败案例，未来可以通过扩大数据集规模、增加数据增强策略、优化网络结构等方式进一步改进。

\subsubsection{不同场景下的性能表现}

表 4-6 给出了不同方法在不同场景下的性能表现。

\begin{table}[htbp]
\centering
\caption{不同场景下的性能表现}
\label{tab:scene_performance}
\begin{tabular}{lccc}
\toprule
场景类型 & DeepLabV3+ (基线) & DeepLabV3+ + ALL & 提升幅度 \\
\midrule
简单场景 & 0.892 & 0.945 & +5.9\% \\
复杂场景 & 0.789 & 0.862 & +9.3\% \\
边界复杂场景 & 0.756 & 0.834 & +10.3\% \\
\bottomrule
\end{tabular}
\end{table}

由表 4-6 可知，本文方法在不同场景下均取得性能提升，且在复杂场景和边界复杂场景下的提升更加明显。简单场景下，mIoU 从 0.892 提升至 0.945，提升幅度为 5.9\%；复杂场景下，mIoU 从 0.789 提升至 0.862，提升幅度为 9.3\%；边界复杂场景下，mIoU 从 0.756 提升至 0.834，提升幅度为 10.3\%，HD95 从 15.89 降低至 11.23，降低幅度为 29.3\%。

这一结果表明，本文方法在复杂场景和边界复杂场景下的提升更加明显，说明双重注意力机制对复杂场景的处理更有效。TR 模块通过全局上下文建模，能够更好地处理复杂形态的目标；SAE 模块通过局部细节增强，能够更好地处理边界复杂的情况。两者结合，使得网络在复杂场景下仍能取得良好的分割效果。

\subsection{效率分析}

在实际应用中，除了分割性能外，模型的计算效率也是重要的考量因素。本节从参数量、内存占用和推理时间三个方面分析不同方法的计算效率，并讨论性能与效率之间的权衡。

\subsubsection{参数量对比}

表 4-7 给出了不同方法的参数量对比。

\begin{table}[htbp]
\centering
\caption{不同方法的参数量对比}
\label{tab:parameter_comparison}
\begin{tabular}{lcc}
\toprule
模型配置 & 参数量(MB) & 相比基线 \\
\midrule
UNet++ & 8.8 & -90.7\% \\
ResUNet & 13 & -86.3\% \\
UNet (基础) & 30 & -68.4\% \\
DeepLabV3+ (基线) & 95 & - \\
DeepLabV3+ + SAE & 120 & +26.3\% \\
TransUNet & 219 & +130.5\% \\
DeepLabV3+ + TR & 396 & +316.8\% \\
\textbf{DeepLabV3+ + ALL} & \textbf{420} & \textbf{+342.1\%} \\
\bottomrule
\end{tabular}
\end{table}

由表 4-7 可知，本文方法的参数量为 420 MB，相比基线模型（95 MB）增加 342.1\%。参数量增加主要来源于 TR 模块（+301 MB）和 SAE 模块（+25 MB）。虽然参数量增加较大，但性能提升显著（mIoU 提升 7.1\%），参数效率合理。

相比 TransUNet（219 MB），本文方法的参数量增加 91.8\%，但性能提升 12.5\%，且内存占用减少 53.3\%，推理时间减少 39.1\%，说明本文方法在性能和效率之间取得了更好的平衡。

\textbf{参数效率分析}：本文方法的参数效率（mIoU 提升/参数量增加）为 0.017，虽然低于 SAE 模块单独使用时的参数效率（0.236），但考虑到 TR 模块的全局建模能力对细长结构分割的重要意义，这一参数效率是可以接受的。在实际应用中，可以根据具体需求选择合适的模型配置：如果对参数量要求较高，可以选择仅使用 SAE 模块的配置；如果对性能要求较高，可以选择完整配置。

\subsubsection{内存占用对比}

表 4-8 给出了不同方法的内存占用对比。

\begin{table}[htbp]
\centering
\caption{不同方法的内存占用对比}
\label{tab:memory_comparison}
\begin{tabular}{lcc}
\toprule
模型配置 & 内存占用(MB) & 相比基线 \\
\midrule
DeepLabV3+ (基线) & 2705 & - \\
UNet (基础) & 3809 & +40.8\% \\
ResUNet & 4351 & +60.8\% \\
UNet++ & 4675 & +72.8\% \\
DeepLabV3+ + SAE & 7011 & +159.0\% \\
DeepLabV3+ + TR & 7004 & +158.7\% \\
\textbf{DeepLabV3+ + ALL} & \textbf{9107} & \textbf{+236.7\%} \\
TransUNet & 19530 & +621.6\% \\
\bottomrule
\end{tabular}
\end{table}

由表 4-8 可知，本文方法的内存占用为 9107 MB，相比基线模型（2705 MB）增加 236.7\%。内存占用增加主要来源于 TR 模块和 SAE 模块的中间特征存储。虽然内存占用增加较大，但相比 TransUNet（19530 MB）减少 53.3\%，说明本文方法在内存占用方面具有优势。

\textbf{内存占用分析}：内存占用主要受模型结构和特征图尺寸影响。TR 模块需要存储窗口划分和注意力计算的中间结果，SAE 模块需要存储坐标注意力和通道注意力的中间特征，这些都会增加内存占用。但在实际应用中，9107 MB 的内存占用在现代 GPU（如 24 GB 显存）上是可以接受的。

\subsubsection{推理时间对比}

表 4-9 给出了不同方法的推理时间对比（单张图像，512×512）。

\begin{table}[htbp]
\centering
\caption{不同方法的推理时间对比}
\label{tab:inference_time}
\begin{tabular}{lccc}
\toprule
模型配置 & 推理时间(ms) & 相比基线 & FPS \\
\midrule
DeepLabV3+ (基线) & 38 & - & 26.3 \\
UNet (基础) & 45 & +18.4\% & 22.2 \\
DeepLabV3+ + SAE & 52 & +36.8\% & 19.2 \\
DeepLabV3+ + TR & 89 & +134.2\% & 11.2 \\
\textbf{DeepLabV3+ + ALL} & \textbf{95} & \textbf{+150.0\%} & \textbf{10.5} \\
TransUNet & 156 & +310.5\% & 6.4 \\
\bottomrule
\end{tabular}
\end{table}

由表 4-9 可知，本文方法的推理时间为 95 ms，相比基线模型（38 ms）增加 150.0\%，FPS 达到 10.5。虽然推理时间增加较大，但仍比 TransUNet（156 ms）快 39.1\%，FPS 也高于 TransUNet（6.4 FPS）。

\textbf{实时性分析}：FPS 达到 10.5，满足实时应用需求（>10 FPS）。在实际应用中，10.5 FPS 的推理速度足以满足大多数实时监测场景的需求。如果对实时性要求更高，可以选择仅使用 SAE 模块的配置（FPS 19.2），虽然性能略有下降，但推理速度更快。

\subsubsection{效率权衡分析}

综合参数量、内存占用和推理时间的分析，本文方法在性能和效率之间取得了良好的平衡：

\textbf{（1）性能与效率的权衡}：虽然本文方法的参数量、内存占用和推理时间相比基线模型均有增加，但性能提升显著（mIoU 提升 7.1\%），且相比 TransUNet 在内存占用和推理时间方面具有优势。这说明本文方法在性能和效率之间取得了良好的平衡。

\textbf{（2）应用场景讨论}：
\begin{itemize}
    \item \textbf{实时性要求高的场景}：如果对实时性要求较高（如在线监测），可以选择仅使用 SAE 模块的配置，FPS 达到 19.2，满足实时应用需求。
    \item \textbf{性能要求高的场景}：如果对性能要求较高（如离线分析），可以选择完整配置，mIoU 达到 0.911，性能最优。
    \item \textbf{资源受限的场景}：如果计算资源受限（如边缘设备），可以考虑模型压缩技术（如知识蒸馏、剪枝、量化等），在保持性能的同时降低资源需求。
\end{itemize}

\textbf{（3）优化方向}：未来可以通过以下方式进一步优化计算效率：
\begin{itemize}
    \item 模型压缩：采用知识蒸馏、剪枝、量化等技术，在保持性能的同时降低参数量和计算复杂度。
    \item 架构优化：优化 TR 模块的窗口划分策略和 TopK 选择机制，进一步降低计算复杂度。
    \item 硬件加速：利用专用硬件（如 TensorRT、ONNX Runtime 等）进行推理加速。
\end{itemize}

综合以上分析，本文方法在保持高性能的同时，具有合理的计算效率，能够满足实际应用的需求。

\subsection{本章小结}

本章对所提出的基于改进 DeepLabV3+ 的 OCT 图像语义分割方法进行了全面的实验验证与分析。通过对比实验、消融实验、可视化分析和效率分析，验证了本文方法的有效性和实用性。

\textbf{（1）性能优势}：本文方法在分割精度、目标类别分割和边界精度等方面均取得显著提升。mIoU 达到 0.911，相比基线模型提升 7.1\%；目标类别 IoU 提升 16.3\%，相比 UNet 提升 33.2\%；边界精度 HD95 降低 12.6\%，边界分割更加精确。

\textbf{（2）效率优势}：本文方法在保持高性能的同时，具有合理的计算效率。相比 TransUNet，内存占用减少 53.3\%，推理时间减少 39.1\%，FPS 达到 10.5，满足实时应用需求。

\textbf{（3）创新性验证}：消融实验验证了双重注意力机制的协同效应，TR 模块和 SAE 模块的组合使用能够取得最优结果。TR 模块负责全局上下文建模，SAE 模块负责局部细节增强，两者结合能够同时处理全局和局部信息，从而取得更好的综合性能。

\textbf{（4）实用性验证}：本文方法采用模块化设计，TR 和 SAE 模块可灵活集成到其他网络架构；参数可配置，支持不同场景的参数调优；工程实现友好，基于 PyTorch 框架，易于部署和优化。

需要指出的是，本文方法仍存在一些不足：在极端噪声条件下可能出现误分割，对形态异常的目标处理能力有限，实时性虽然满足基本需求，但仍有优化空间。这些不足为未来的研究工作指明了方向。

综合以上实验结果和分析，本文方法在 OCT 图像语义分割任务中取得了良好的性能，验证了所提方法的有效性，为后续章节的总结与展望提供了实验支撑。