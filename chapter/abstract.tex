\begin{abstractCN}
\setlength{\baselineskip}{23pt} %设置行距23磅

光学相干断层扫描（OCT）图像语义分割是激光焊接熔池检测等工业视觉任务中的关键环节。受散斑噪声、边界模糊及目标与背景对比不足等因素影响，常规卷积分割模型易出现全局语义理解不足与局部边界刻画不精的现象。针对上述问题，本文提出一种基于改进DeepLabV3+的OCT图像语义分割方法。

该方法以DeepLabV3+为基础框架，结合多尺度上下文聚合与注意力建模：在ASPP输出后引入TR（Transformer Routing）模块以增强全局上下文表达，提升对长程依赖与整体结构的刻画能力；在解码器高低层特征融合后引入SAE（Spatial Attention Enhancement）模块以强化局部细节与边界信息表征；同时采用交叉熵损失与Dice损失的组合以缓解类别不平衡带来的训练偏置。

本文工作的主要贡献体现在：面向OCT图像分割“全局语义不足—局部边界不清”的矛盾，在统一的编码器—解码器框架内协同引入全局与局部注意力机制，使网络在保持多尺度表征能力的同时进一步强化对关键区域与边界的判别；并通过损失函数设计提升对小目标与类别不平衡场景的适应性，从而提高分割结果的稳定性与可用性。

在包含912张训练图像与228张测试图像的OCT数据集上，所提方法取得mIoU为0.911，较基线DeepLabV3+提升7.1\%，目标类别IoU提升16.3\%。实验结果表明，所提出方法能够兼顾全局语义理解与局部边界刻画，为OCT图像的高精度分割与工程应用提供有效支撑。

\end{abstractCN}


\begin{keywordCN}
语义分割；DeepLabV3+；注意力机制；OCT图像；激光焊接
\end{keywordCN}

\begin{abstractEN}
\setlength{\baselineskip}{23pt} %设置行距23磅

Optical Coherence Tomography (OCT) image semantic segmentation is a critical component in industrial vision applications such as laser welding molten pool inspection. Due to speckle noise, blurred boundaries, and weak contrast between the target and background, conventional convolutional segmentation models often suffer from limited global context understanding and inaccurate boundary delineation. To address these challenges, we propose an improved DeepLabV3+-based method for OCT image semantic segmentation.

Built upon the DeepLabV3+ encoder--decoder architecture, the proposed approach integrates attention modeling to balance global semantics and local details. Specifically, a TR (Transformer Routing) module is introduced after ASPP to enhance global context representation and long-range dependency modeling, while an SAE (Spatial Attention Enhancement) module is applied after decoder feature fusion to strengthen local detail and boundary-aware features. In addition, a hybrid loss combining cross-entropy and Dice loss is adopted to mitigate class imbalance during training.

The main contributions are three-fold: (1) a unified enhancement scheme that jointly improves global semantic understanding and local boundary characterization for OCT images by combining global and local attention in a single encoder--decoder framework; (2) improved robustness to challenging cases such as small target regions and severe class imbalance via a hybrid loss; and (3) a practical segmentation solution that is readily applicable to high-precision industrial inspection scenarios.

Experiments on an OCT dataset with 912 training images and 228 test images demonstrate that the proposed method achieves an mIoU of 0.911, outperforming the baseline DeepLabV3+ by 7.1\%, with the target-class IoU improved by 16.3\%. These results indicate that the proposed method effectively improves OCT segmentation performance and provides practical value for high-precision industrial inspection.

\end{abstractEN}

\begin{keywordEN}
Semantic Segmentation; DeepLabV3+; Attention Mechanism; OCT Image; Laser Welding
\end{keywordEN}



\begin{signAndABC}

\begin{adjustwidth}{-\leftskip}{0pt}
 % 调整表格宽度
\renewcommand\arraystretch{1.5}
\begin{tabular}{l@{\hspace{4em}}l}
OCT & 光学相干断层扫描（Optical Coherence Tomography） \\
ASPP & 空洞空间金字塔池化（Atrous Spatial Pyramid Pooling） \\
TR & 变换器路由（Transformer Routing） \\
SAE & 空间注意力增强（Spatial Attention Enhancement） \\
mIoU & 平均交并比（Mean Intersection over Union） \\
mAcc & 平均准确率（Mean Accuracy） \\
HD95 & 豪斯多夫距离95\%分位数（95th Percentile Hausdorff Distance） \\
\end{tabular}
\end{adjustwidth}


\end{signAndABC}


